# DataLeakage_ML

Identify Data Leakage in Machine Learning Models

In this project, we will investigate the factors influencing student outcomes—Dropout, Enrolled, or Graduate—using machine learning techniques, including decision tree and random forest classifiers. A central focus of this project is understanding and addressing data leakage, a critical issue in machine learning where features inadvertently provide information about the target variable that would not be available at prediction time. Data leakage often leads to inflated performance metrics, misleading model interpretations, and poor generalization to unseen data.

By carefully analyzing feature selection and model outputs, we will demonstrate how to identify and mitigate data leakage. Through this process, learners will build robust, interpretable models that deliver fair and realistic predictions. The project highlights the importance of ensuring that only valid predictors are used, maintaining the integrity of the modeling pipeline.

This project provides a step-by-step guide to building interpretable machine learning models, diagnosing data leakage, and understanding its impact on model performance and generalization.
